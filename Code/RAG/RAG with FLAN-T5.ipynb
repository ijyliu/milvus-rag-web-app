{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG with FLAN-T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "from RAG_Functions import *\n",
    "import time\n",
    "from pymilvus import Collection, connections\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 1024, 'pooling_mode_cls_token': True, 'pooling_mode_mean_tokens': False, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedding model\n",
    "embedding_model = SentenceTransformer(\"mixedbread-ai/mxbai-embed-large-v1\")\n",
    "embedding_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "chat_tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "chat_model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Milvus Connection and Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "connections.connect(host='localhost', port='19530')\n",
    "collection = Collection(\"text_embeddings\")      # Get an existing collection.\n",
    "collection.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Reddit: We may share information about you with your consent or at your direction.', 'Reddit: You have choices about how to protect and limit the collection, use, and sharing of information about you when you use the Services.', 'Reddit: We may share information if we believe your actions are inconsistent with our User Agreement, rules, or other Reddit policies, or to protect the rights, property, and safety of ourselves and others.', 'Reddit: You may also provide other account information, like an email address, bio, or profile picture.', 'Reddit: We may share information about you that has been aggregated or anonymized such that it cannot reasonably be used to identify you.']\n"
     ]
    }
   ],
   "source": [
    "# Chat with model\n",
    "input_text = input()\n",
    "\n",
    "# Get embedding of input\n",
    "input_embedding = get_mixedbread_of_query(embedding_model, input_text)\n",
    "\n",
    "# Start timing query\n",
    "start_time = time.time()\n",
    "\n",
    "# Top5 sentences\n",
    "top5_sentences = return_top_5_sentences(collection, input_embedding)\n",
    "\n",
    "# End timing query\n",
    "end_time = time.time()\n",
    "\n",
    "print(top5_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:\n",
      "Reddit: We may share information about you with your consent or at your direction.\n",
      "Reddit: You have choices about how to protect and limit the collection, use, and sharing of information about you when you use the Services.\n",
      "Reddit: We may share information if we believe your actions are inconsistent with our User Agreement, rules, or other Reddit policies, or to protect the rights, property, and safety of ourselves and others.\n",
      "Reddit: You may also provide other account information, like an email address, bio, or profile picture.\n",
      "Reddit: We may share information about you that has been aggregated or anonymized such that it cannot reasonably be used to identify you.\n",
      "User Query:\n",
      "What does Reddit say about using my personal information?\n"
     ]
    }
   ],
   "source": [
    "# Construct prompt\n",
    "prompt_lines = [\"Context:\"] + top5_sentences + [\"User Query:\\n\" + input_text]\n",
    "prompt = \"\\n\".join(prompt_lines)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> We may share information about you that has been aggregated or anonymized such that it cannot reasonably be used to identify you.</s>\n"
     ]
    }
   ],
   "source": [
    "# Tokenize\n",
    "input_ids = chat_tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "# Generate\n",
    "outputs = chat_model.generate(input_ids, max_new_tokens = 100)\n",
    "print(chat_tokenizer.decode(outputs[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_engineering_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
